{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the yearly percentage of flights cancelled for each reason (A = carrier, B = weather, C = NAS, D = security)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset is composed in this way:\n",
    "\n",
    "<br>1 Year -> 1994-2008 \n",
    "<br>2 Month -> 1-12\n",
    "<br>3 DayofMonth -> 1-31\n",
    "<br>4 DayOfWeek -> 1 (Monday) - 7 (Sunday)\n",
    "<br>5 DepTime -> actual departure time (local, hhmm)\n",
    "<br>6 CRSDepTime -> scheduled departure time (local, hhmm)\n",
    "<br>7 ArrTime -> actual arrival time (local, hhmm)\n",
    "<br>8 CRSArrTime -> scheduled arrival time (local, hhmm)\n",
    "<br>9 UniqueCarrier -> unique carrier code\n",
    "<br>10 FlightNum -> flight number\n",
    "<br>11 TailNum -> plane tail number\n",
    "<br>12 ActualElapsedTime -> in minutes\n",
    "<br>13 CRSElapsedTime -> in minutes\n",
    "<br>14 AirTime -> in minutes\n",
    "<br>15 ArrDelay -> arrival delay, in minutes\n",
    "<br>16 DepDelay -> departure delay, in minutes\n",
    "<br>17 Origin -> origin IATA airport code\n",
    "<br>18 Dest -> destination IATA airport code\n",
    "<br>19 Distance -> in miles\n",
    "<br>20 TaxiIn -> taxi in time, in minutes\n",
    "<br>21 TaxiOut -> taxi out time in minutes\n",
    "<br>22 Cancelled -> was the flight cancelled?\n",
    "<br>23 CancellationCode -> reason for cancellation\n",
    "        (A = carrier, B = weather, C = NAS, D = security)\n",
    "<br>24 Diverted -> 1 = yes, 0 = no\n",
    "<br>25 CarrierDelay -> in minutes\n",
    "<br>26 WeatherDelay -> in minutes\n",
    "<br>27 NASDelay -> in minutes\n",
    "<br>28 SecurityDelay -> in minutes\n",
    "<br>29 LateAircraftDelay -> in minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import to_date, col, lit, concat, weekofyear\n",
    "from pyspark.sql.types import IntegerType\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadYearCsv(year):\n",
    "    filePath = \"./Data/\"+str(year)+\".csv\"\n",
    "\n",
    "#load dataset from csv file and then creates a dataframe \n",
    "    df = sqlContext.read.csv(filePath, header='true')\n",
    "\n",
    "#DataFrame[Year, CancellationCode]\n",
    "    df = df.select(\"Year\", \"CancellationCode\", \"Cancelled\" ) \n",
    "    df = df.orderBy(\"Year\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasonsCancellation(year):    \n",
    "    \n",
    "    #loads data \n",
    "    #DataFrame[Year, CancellationCode]\n",
    "    df = loadYearCsv(year)\n",
    "    \n",
    "    #df0 contains the total amount of flights with a cancellation code\n",
    "    df0 = df.filter(col(\"CancellationCode\") != 'NA').filter(col(\"CancellationCode\") != 'null').groupBy(\"Year\").count() \\\n",
    "            .withColumnRenamed(\"count\", \"Total\")\n",
    "    \n",
    "    #dfA contains the amount of flights with cancellation code A\n",
    "    dfA = df.filter(col(\"CancellationCode\") == 'A').groupBy(\"Year\").count() \\\n",
    "            .withColumnRenamed(\"count\", \"ACanc\")\n",
    "    \n",
    "    #dfB contains the amount of flights with cancellation code B\n",
    "    dfB = df.filter(col(\"CancellationCode\") == 'B').groupBy(\"Year\").count() \\\n",
    "            .withColumnRenamed(\"count\", \"BCanc\") \n",
    "\n",
    "    #dfC contains the amount of flights with cancellation code C\n",
    "    dfC = df.filter(col(\"CancellationCode\") == 'C').groupBy(\"Year\").count() \\\n",
    "            .withColumnRenamed(\"count\", \"CCanc\") \n",
    "\n",
    "    #dfD contains the amount of flights with cancellation code D\n",
    "    dfD = df.filter(col(\"CancellationCode\") == 'D').groupBy(\"Year\").count()  \\\n",
    "            .withColumnRenamed(\"count\", \"DCanc\")\n",
    "    \n",
    "    dfFinal = df0.join(dfA, \"Year\")\n",
    "    dfFinal = dfFinal.join(dfB, \"Year\")\n",
    "    dfFinal = dfFinal.join(dfC, \"Year\")\n",
    "    dfFinal = dfFinal.join(dfD, \"Year\")\n",
    "    \n",
    "    #computes the percentage\n",
    "    dfFinal = dfFinal.withColumn(\"PercA\", dfFinal[\"ACanc\"]/dfFinal[\"Total\"])\n",
    "    dfFinal = dfFinal.withColumn(\"PercB\", dfFinal[\"BCanc\"]/dfFinal[\"Total\"])\n",
    "    dfFinal = dfFinal.withColumn(\"PercC\", dfFinal[\"CCanc\"]/dfFinal[\"Total\"])\n",
    "    dfFinal = dfFinal.withColumn(\"PercD\", dfFinal[\"DCanc\"]/dfFinal[\"Total\"])\n",
    "\n",
    "    return dfFinal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalPath = \"./Results/Query5/query5.csv\"\n",
    "years = list(range(1994, 2009,1))\n",
    "\n",
    "with open(finalPath, 'a') as f:\n",
    "    for y in years:\n",
    "        tmpDf = reasonsCancellation(y)\n",
    "        if (y==1994):\n",
    "            tmpDf.toPandas().to_csv(f, header=True)\n",
    "        else:\n",
    "            tmpDf.toPandas().to_csv(f, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
